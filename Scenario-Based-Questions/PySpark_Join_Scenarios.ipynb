{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# PySpark Join Scenarios - From Basic to Pro\n", "This notebook includes various PySpark join scenarios with code and explanations."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["from pyspark.sql import SparkSession\n", "from pyspark.sql.functions import expr, broadcast\n", "\n", "spark = SparkSession.builder.appName("JoinScenarios").getOrCreate()\n", "\n", "# Sample DataFrames\n", "employees = spark.createDataFrame([\n", "    (1, "Alice", 10),\n", "    (2, "Bob", None),\n", "    (3, "Charlie", 20),\n", "], ["id", "name", "dept_id"])\n", "\n", "departments = spark.createDataFrame([\n", "    (10, "HR"),\n", "    (20, "Engineering"),\n", "    (30, "Marketing")\n", "], ["dept_id", "dept_name"])\n", "\n", "employees.show()\n", "departments.show()"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# 1. Employees with valid departments (Inner Join)\n", "employees.join(departments, on="dept_id", how="inner").show()"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# 2. Employees without departments (Left Anti Join)\n", "employees.join(departments, on="dept_id", how="left_anti").show()"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["# 3. All employees with departments (even if department is missing)\n", "employees.join(departments, on="dept_id", how="left").show()"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["# 4. Null-safe join on nullable dept_id\n", "employees.join(departments, expr("employees.dept_id <=> departments.dept_id")).show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 2}