{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3275cbdd-7074-412e-8203-0e0273233869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Scenario: Calculate the total salary per department and sort them by total salary in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8514410-782b-4ed4-b401-d05a4387f38c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n| name|department|salary|\n+-----+----------+------+\n|Alice|        HR| 50000|\n|  Bob|        IT| 70000|\n|Carol|        IT| 80000|\n| Dave|        HR| 55000|\n|  Eve|   Finance| 60000|\n|Frank|   Finance| 65000|\n|Grace|        IT| 75000|\n+-----+----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum \n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"Alice\", \"HR\", 50000),\n",
    "    (\"Bob\", \"IT\", 70000),\n",
    "    (\"Carol\", \"IT\", 80000),\n",
    "    (\"Dave\", \"HR\", 55000),\n",
    "    (\"Eve\", \"Finance\", 60000),\n",
    "    (\"Frank\", \"Finance\", 65000),\n",
    "    (\"Grace\", \"IT\", 75000)\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"department\", \"salary\"]\n",
    "\n",
    "# Create DataFrame\n",
    "emp = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show the original DataFrame\n",
    "emp.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f296db87-ad15-4977-86cc-b01b008e74ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n|department|total_salary|\n+----------+------------+\n|        IT|      225000|\n|   Finance|      125000|\n|        HR|      105000|\n+----------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Calculate total salary per department and sort descending\n",
    "dept_salary_df = emp.groupBy(\"department\").agg(\n",
    "    sum(\"salary\").alias(\"total_salary\")\n",
    ").orderBy(\"total_salary\" , ascending = False)\n",
    "\n",
    "# Show result\n",
    "dept_salary_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea48a60d-e2b1-4628-827d-8b70281a9a52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2.Scenario: Find the highest and lowest salary per department You are given a dataset with employee details (name, department, salary). How would you find the highest and lowest salary in each department?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542c139f-10cc-44e6-a3de-0968c7a089d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n|   name|department|salary|\n+-------+----------+------+\n|  Alice|        HR| 50000|\n|    Bob|        HR| 60000|\n|Charlie|        IT| 70000|\n|  David|        IT| 90000|\n|    Eve|     Sales| 45000|\n|  Frank|     Sales| 55000|\n+-------+----------+------+\n\n+----------+----------+----------+\n|department|max_salary|min_salary|\n+----------+----------+----------+\n|        HR|     60000|     50000|\n|        IT|     90000|     70000|\n|     Sales|     55000|     45000|\n+----------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max, min\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"SalaryStats\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"Alice\", \"HR\", 50000),\n",
    "    (\"Bob\", \"HR\", 60000),\n",
    "    (\"Charlie\", \"IT\", 70000),\n",
    "    (\"David\", \"IT\", 90000),\n",
    "    (\"Eve\", \"Sales\", 45000),\n",
    "    (\"Frank\", \"Sales\", 55000)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show original data\n",
    "df.show()\n",
    "\n",
    "# Find highest and lowest salary per department\n",
    "result_df = df.groupBy(\"department\").agg(\n",
    "    max(\"salary\").alias(\"max_salary\"),\n",
    "    min(\"salary\").alias(\"min_salary\")\n",
    ")\n",
    "\n",
    "# Show result\n",
    "result_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c03d30cc-555e-42f3-bba1-2dfc54614243",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Scenario: Count the number of employees in each department and identify departments with fewer than 5 employees.\n",
    "### Question: Given a dataset with employee details (name, department, salary), how would you count the number of employees in each department and filter out the departments with fewer than 5 employees?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a475312f-b991-4f8f-909d-0c74ed7506b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n|department|employee_count|\n+----------+--------------+\n|        HR|             2|\n|        IT|             3|\n+----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"Alice\", \"HR\", 50000),\n",
    "    (\"Bob\", \"HR\", 60000),\n",
    "    (\"Charlie\", \"IT\", 70000),\n",
    "    (\"David\", \"IT\", 90000),\n",
    "    (\"Eve\", \"Sales\", 45000),\n",
    "    (\"Frank\", \"Sales\", 55000),\n",
    "    (\"Grace\", \"Sales\", 47000),\n",
    "    (\"Hank\", \"Sales\", 52000),\n",
    "    (\"Ivy\", \"Sales\", 49000),\n",
    "    (\"Jack\", \"IT\", 75000)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "columns = [\"name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Count employees per department\n",
    "dept_counts = df.groupBy(\"department\").agg(count(\"*\").alias(\"employee_count\"))\n",
    "\n",
    "# Filter departments with fewer than 5 employees\n",
    "filtered_depts = dept_counts.filter(\"employee_count < 5\")\n",
    "\n",
    "# Show result\n",
    "filtered_depts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d743fd8c-b147-4f9b-b533-93852be935b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 4.Scenario: Find the average salary of employees in each department and compare it to the overall average salary.\n",
    "### Question: You are given a dataset of employee details. How would you find the average salary in each department and then compare it to the overall average salary?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dec03a9-a6b8-41bb-9c40-bdea74ac63a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+\n|   name|department|salary|\n+-------+----------+------+\n|  Alice|        HR| 50000|\n|    Bob|        HR| 60000|\n|Charlie|        IT| 70000|\n|  David|        IT| 90000|\n|    Eve|     Sales| 45000|\n|  Frank|     Sales| 55000|\n|  Grace|     Sales| 47000|\n|   Hank|     Sales| 52000|\n|    Ivy|     Sales| 49000|\n|   Jack|        IT| 75000|\n+-------+----------+------+\n\n+----------+-----------------+------------------+------------------+\n|department|  avg_salary_dept|overall_avg_salary|above_or_below_avg|\n+----------+-----------------+------------------+------------------+\n|        HR|          55000.0|           -4300.0|             false|\n|        IT|78333.33333333333| 19033.33333333333|              true|\n|     Sales|          49600.0|           -9700.0|             false|\n+----------+-----------------+------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col\n",
    "\n",
    "# Step 2: Sample employee data\n",
    "data = [\n",
    "    (\"Alice\", \"HR\", 50000),\n",
    "    (\"Bob\", \"HR\", 60000),\n",
    "    (\"Charlie\", \"IT\", 70000),\n",
    "    (\"David\", \"IT\", 90000),\n",
    "    (\"Eve\", \"Sales\", 45000),\n",
    "    (\"Frank\", \"Sales\", 55000),\n",
    "    (\"Grace\", \"Sales\", 47000),\n",
    "    (\"Hank\", \"Sales\", 52000),\n",
    "    (\"Ivy\", \"Sales\", 49000),\n",
    "    (\"Jack\", \"IT\", 75000)\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Show the original DataFrame\n",
    "df.show()\n",
    "\n",
    "# Step 3: Calculate average salary per department\n",
    "avg_salary_dept = df.groupBy(\"department\").agg(avg(\"salary\").alias(\"avg_salary_dept\"))\n",
    "\n",
    "# Step 4: Calculate overall average salary\n",
    "overall_avg_salary_row = df.agg(avg(\"salary\").alias(\"overall_avg_salary\")).collect()[0]\n",
    "overall_avg_salary = overall_avg_salary_row[\"overall_avg_salary\"]\n",
    "\n",
    "# Step 5: Add a column to compare with overall average\n",
    "comparison_df = avg_salary_dept.withColumn(\"overall_avg_salary\", col(\"avg_salary_dept\") - overall_avg_salary)\n",
    "\n",
    "# Optional: Add a column to indicate whether dept avg is above or below overall\n",
    "comparison_df = comparison_df.withColumn(\n",
    "    \"above_or_below_avg\",\n",
    "    col(\"overall_avg_salary\") > 0\n",
    ")\n",
    "\n",
    "# Show the final result\n",
    "comparison_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d5fad17-befb-4ba7-80de-4c69b1147a89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  5.Scenario: Find departments with the maximum number of employees.\n",
    "### Question: You are given a dataset with employee details. How would you find which department has the most employees?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99fadb76-6ba6-4b1c-b971-3b531fafd960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n|department|employee_count|\n+----------+--------------+\n|        IT|             4|\n|        HR|             2|\n|   Finance|             2|\n+----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"MaxEmployeesByDept\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"Alice\", \"HR\"),\n",
    "    (\"Bob\", \"IT\"),\n",
    "    (\"Carol\", \"IT\"),\n",
    "    (\"Dave\", \"HR\"),\n",
    "    (\"Eve\", \"Finance\"),\n",
    "    (\"Frank\", \"Finance\"),\n",
    "    (\"Grace\", \"IT\"),\n",
    "    (\"Hank\", \"IT\")\n",
    "]\n",
    "\n",
    "columns = [\"name\", \"department\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Count employees per department and sort by count descending\n",
    "dept_counts = df.groupBy(\"department\").agg(\n",
    "    count(\"name\").alias(\"employee_count\")\n",
    ").orderBy(\"employee_count\", ascending=False)\n",
    "\n",
    "# Show result\n",
    "dept_counts.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Scenario Based Questions List - 1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}